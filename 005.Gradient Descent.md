# Gradient Descent

## Definition of gradient descent

- In mathematics, gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.

- The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent.

- It is particularly useful in machine learning for minimizing the cost or loss function.

- An optimization algorithm is a computer program that helps find the best solution to a problem by systematically trying different possibilities.

## Intuition behind gradient descent

The intuition behind gradient descent can be understood as follows:

Imagine you are standing on a mountain, and your goal is to reach the lowest point (the valley) as quickly as possible. You want to take steps that minimize your altitude (i.e., descend).

1. **Current Position:** You start at a random point on the mountain. This point represents your initial guess for the solution to an optimization problem.

2. **Direction of Steepest Descent:** At your current position, you want to know which way to move to descend the fastest. To do this, you calculate the gradient, which is like a compass telling you the direction of the steepest slope. The gradient represents the rate of change of the function you are trying to optimize.

3. **Step Size:** You also need to decide how large of a step to take. If you take a big step, you might overshoot the valley, and if you take a small step, progress will be slow. This step size is called the learning rate.

4. **Update Position:** You move in the direction of the negative gradient (opposite to the direction of increasing function value) by the distance determined by the learning rate. This is your next position.

5. **Repeat:** You repeat this process, recalculating the gradient at each new position and updating your location. The aim is to keep moving in the direction of steepest descent until you reach the bottom of the valley, which corresponds to the optimal solution of your problem.

The idea is that by iteratively following the gradient and adjusting the step size, you should eventually reach the lowest point in your problem's solution space, which corresponds to the minimum of the function you are trying to optimize. This process is known as gradient descent, and it's widely used in various optimization problems, especially in machine learning when training models to minimize error or loss functions.

## Cost function for linear regression

The cost function for linear regression is often the Mean Squared Error (MSE):

$$
\
J(\theta) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})^2
\
$$

$$
\
\nabla J(\theta) = \begin{bmatrix}
\frac{\partial J(\theta)}{\partial \theta_0} \\
\frac{\partial J(\theta)}{\partial \theta_1}
\end{bmatrix}
\
$$

The partial derivatives are calculated as follows:

1. **Partial Derivative with Respect to (θ_0)**:

   $$
   \
   \frac{\partial J(\theta)}{\partial \theta_0} = \frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})
   \
   $$

2. **Partial Derivative with Respect to (θ_1)**:

   $$
   \
   \frac{\partial J(\theta)}{\partial \theta_1} = \frac{1}{m}\sum_{i=1}^{m}[(h_{\theta}(x^{(i)}) - y^{(i)}) \cdot x^{(i)}]
   \
   $$


## Mathematical formulation of gradient descent

Gradient descent is a mathematical optimization algorithm used to minimize a differentiable function. Here's the mathematical formulation of gradient descent:

1. **Objective Function:** Start with an objective function, often denoted as **J(θ)**, where **θ** represents a set of parameters that you want to adjust in order to minimize the function.

2. **Gradient Calculation:** Calculate the gradient of the objective function with respect to the parameters **θ**. The gradient, denoted as **∇J(θ)**, represents the direction of the steepest ascent, and it points towards the direction of the fastest increase in the function. It is a vector containing partial derivatives of the function with respect to each parameter in **θ**.

3. **Update Rule:** Update the parameters **θ** in the direction of the negative gradient to minimize the function. This is done iteratively according to the following update rule:

    $$
    \
    \theta_{\text{new}} = \theta_{\text{old}} - \alpha \nabla J(\theta_{\text{old}})
    \
    $$

   - **θ_new** is the updated parameter vector.
   - **θ_old** is the current parameter vector.
   - **α** is the learning rate, a positive scalar that determines the step size for the update. It controls how large a step you take in the direction of the gradient.
   - **∇J(θ_old)** is the gradient of the objective function with respect to the parameters **θ_old**.

4. **Iteration:** Repeat this process for a predefined number of iterations or until a stopping criterion is met. The stopping criterion could be reaching a certain convergence threshold, where the change in the objective function becomes very small, or other conditions depending on the specific problem.

The goal of gradient descent is to iteratively update the parameters **θ** in the direction that reduces the value of the objective function **J(θ)** until it converges to a local or global minimum, depending on the characteristics of the function. The choice of learning rate is crucial, as it affects the convergence rate and the algorithm's stability.

Different variants of gradient descent, such as stochastic gradient descent (SGD), mini-batch gradient descent, and others, adapt the update rule and learning rate strategies to improve efficiency and effectiveness in various optimization scenarios, particularly in machine learning and deep learning.

## Effect of learning rate

The learning rate in gradient descent plays a significant role in the training of linear regression models. Linear regression is a simple and commonly used supervised machine learning algorithm for modeling the relationship between a dependent variable and one or more independent variables. Here, we'll discuss the effects of the learning rate in the context of gradient descent for linear regression:

1. **Convergence Speed**:
   - **High Learning Rate**: With a high learning rate, the gradient descent algorithm converges more quickly. It takes larger steps during each iteration, which can be advantageous if the data is well-behaved and the cost function is reasonably well-behaved. However, it's crucial to monitor the algorithm to ensure it doesn't overshoot the minimum and cause oscillations.

   - **Low Learning Rate**: A low learning rate slows down convergence, but it can be beneficial if the cost function has a narrow, deep minimum or if the data is noisy. The smaller steps reduce the risk of overshooting and may help the algorithm reach the minimum smoothly.

2. **Stability and Divergence**:
   - An inappropriate learning rate, whether too high or too low, can lead to instability and divergence. If the learning rate is excessively high, it may cause the algorithm to diverge, meaning it will not reach the minimum and may produce increasingly large errors. Conversely, a very low learning rate might cause extremely slow convergence or stall the algorithm.

3. **Overfitting**:
   - In the context of linear regression, a high learning rate can lead to overfitting. This means that the model fits the training data too closely, capturing noise rather than the underlying pattern. A moderate learning rate is often preferred to maintain a balance between training data fitting and generalization.

4. **Regularization Interaction**:
   - If you're using regularization techniques like L1 (Lasso) or L2 (Ridge) regularization in linear regression, the choice of learning rate can interact with these techniques. High learning rates may weaken the impact of regularization, potentially leading to overfitting, while very low learning rates can diminish the effectiveness of regularization.

5. **Model Performance**:
   - The learning rate can significantly affect the performance of your linear regression model. A well-chosen learning rate helps ensure the model reaches an optimal solution, balancing speed and accuracy in the convergence process.

In linear regression, you often have a convex cost function, making it relatively easy to find a minimum.

Typically, a moderate learning rate is a safe choice, as it balances convergence speed and stability.

Experimentation with different learning rates and careful monitoring of the algorithm's progress can help identify the best learning rate for your specific linear regression problem.

## Types of gradient descent

Gradient descent is a popular optimization algorithm used to minimize a cost function or loss function in machine learning and other optimization problems. There are different variations or types of gradient descent, each with its own approach to updating model parameters. The main types of gradient descent are:

1. **Batch Gradient Descent (BGD):**
   - **Approach**: In BGD, the entire training dataset is used to compute the gradient of the cost function in each iteration. This means that for every update, you sum the gradients of the entire training dataset.
   - **Mathematical Formula**:

    $$
     \
     \theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla J(\theta_{\text{old}})
     \
    $$

   - **Pros**: BGD provides accurate and stable updates to model parameters.
   - **Cons**: It can be computationally expensive, especially with large datasets.

2. **Stochastic Gradient Descent (SGD):**
   - **Approach**: In SGD, a single randomly chosen data point (or a small random mini-batch) is used to compute the gradient in each iteration. This introduces randomness and can lead to faster convergence, but with more variance in parameter updates.
   - **Mathematical Formula**:

    $$
     \
     \theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla J(\theta^{(i)})
     \
    $$

   - **Pros**: Faster convergence and works well with large datasets.
   - **Cons**: More noisy updates that can lead to oscillations.

3. **Mini-Batch Gradient Descent:**
   - **Approach**: Mini-batch gradient descent is a compromise between BGD and SGD. It uses a randomly chosen subset of the training data (mini-batch) to compute the gradient. This balances the computational efficiency of SGD with the stability of BGD.
   - **Mathematical Formula**: Similar to SGD, but the gradient is computed for a mini-batch of data.

    $$
    \
    \theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla J(\theta_{\text{old}}, \text{Mini-Batch})
    \
    $$

   - **Pros**: Good trade-off between computational efficiency and stability.
   - **Cons**: Still has some variance in updates.

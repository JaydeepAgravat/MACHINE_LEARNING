# Introduction to Machine Learning

## Machine Learning

Machine learning is a type of artificial intelligence that enables computers to learn without explicit programming. It involves using algorithms to learn from data and make predictions. It's applied to various domains such as image recognition, natural language processing, and fraud detection.

### Implicit Programming vs Explicit Programming

- Explicit programming involves writing step-by-step instructions for computers.
- Machine learning learns from data and improves over time, without explicit programming.
- This results in adaptable systems capable of handling complex tasks with accuracy.

### Use Cases of Machine Learning

- Machine learning is flexible and powerful compared to explicit programming.
- **Email Classification:**
  - Automates sorting emails into categories like "spam" or "important."
- **Dog Breed Classification:**
  - Identifies dog breeds accurately by learning from images.
- **Data Mining:**
  - Identifies patterns and relationships in large datasets.

### History of Machine Learning

- Origins in the 1940s-1950s; machines learning from data.
- Growth in the 1980s-1990s limited by computing power and data.
- Early 2000s saw a boom due to computing power and data availability.
- Cloud computing, big data, and deep learning accelerated progress.
- Deep learning made strides in 2015-2016.
- Increased accessibility to mathematical tools contributed to its popularity.

## Artificial Intelligence vs Machine Learning vs Deep Learning

- AI seeks smart machines, ML facilitates learning from data, DL uses networks for complex tasks.
- AI aims for smart machines, ML enables data-based learning, DL employs networks for complex learning.
- All concepts contribute to improvement.

### Why Machine Learning When We Have Deep Learning

- ML used with limited data or for simpler solutions.
- DL suitable for complex tasks but requires abundant data and power.
- ML involves manual feature crafting; DL automates feature learning.
- Example: ML for basic weather prediction, DL for accurate predictions with extensive data.

## Types of Machine Learning

### Based on Learning Style

#### 1. Supervised Machine Learning

As its name suggests, **Supervised Machine Learning** is based on supervision. It means in the supervised learning technique, we train the machines using the "labelled" dataset, and based on the training, the machine predicts the output. Here, the labelled data specifies that some of the inputs are already mapped to the output. More preciously, we can say; first, we train the machine with the input and corresponding output, and then we ask the machine to predict the output using the test dataset.

Let's understand supervised learning with an example. Suppose we have an input dataset of cats and dog images. So, first, we will provide the training to the machine to understand the images, such as the shape & size of the tail of cat and dog, Shape of eyes, colour, height (dogs are taller, cats are smaller), etc. After completion of training, we input the picture of a cat and ask the machine to identify the object and predict the output. Now, the machine is well trained, so it will check all the features of the object, such as height, shape, colour, eyes, ears, tail, etc., and find that it's a cat. So, it will put it in the Cat category. This is the process of how the machine identifies the objects in Supervised Learning.

The main goal of the supervised learning technique is to map the input variable(x) with the output variable(y). Some real-world applications of supervised learning are Risk Assessment, Fraud Detection, Spam filtering, etc.

##### Categories of Supervised Machine Learning

Supervised machine learning can be classified into two types of problems, which are given below:

1. **Classification**
2. **Regression**

a) **Classification**
Classification algorithms are used to solve the classification problems in which the output variable is categorical, such as "Yes" or No, Male or Female, Red or Blue, etc. The classification algorithms predict the categories present in the dataset. Some real-world examples of classification algorithms are Spam Detection, Email filtering, etc.

Some popular classification algorithms are given below:

- Random Forest Algorithm
- Decision Tree Algorithm
- Logistic Regression Algorithm
- Support Vector Machine Algorithm

b) **Regression**
Regression algorithms are used to solve regression problems in which there is a linear relationship between input and output variables. These are used to predict continuous output variables, such as market trends, weather prediction, etc.

Some popular Regression algorithms are given below:

- Simple Linear Regression Algorithm
- Multivariate Regression Algorithm
- Decision Tree Algorithm
- Lasso Regression

##### Advantages and Disadvantages of Supervised Learning

**Advantages:**

- Since supervised learning work with the labelled dataset so we can have an exact idea about the classes of objects.
- These algorithms are helpful in predicting the output on the basis of prior experience.

**Disadvantages:**

- These algorithms are not able to solve complex tasks.
- It may predict the wrong output if the test data is different from the training data.
- It requires lots of computational time to train the algorithm.

##### Applications of Supervised Learning

Some common applications of Supervised Learning are given below:

- Image Segmentation: Supervised Learning algorithms are used in image segmentation. In this process, image classification is performed on different image data with pre-defined labels.
- Medical Diagnosis: Supervised algorithms are also used in the medical field for diagnosis purposes. It is done by using medical images and past labelled data with labels for disease conditions. With such a process, the machine can identify a disease for the new patients.
- Fraud Detection: Supervised Learning classification algorithms are used for identifying fraud transactions, fraud customers, etc. It is done by using historic data to identify the patterns that can lead to possible fraud.
- Spam Detection: In spam detection & filtering, classification algorithms are used. These algorithms classify an email as spam or not spam. The spam emails are sent to the spam folder.
- Speech Recognition: Supervised learning algorithms are also used in speech recognition. The algorithm is trained with voice data, and various identifications can be done using the same, such as voice-activated passwords, voice commands, etc.

#### 2. Unsupervised Machine Learning

**Unsupervised learning** is different from the Supervised learning technique; as its name suggests, there is no need for supervision. It means, in unsupervised machine learning, the machine is trained using the unlabeled dataset, and the machine predicts the output without any supervision.

In unsupervised learning, the models are trained with the data that is neither classified nor labelled, and the model acts on that data without any supervision.

The main aim of the unsupervised learning algorithm is to group or categories the unsorted dataset according to the similarities, patterns, and differences. Machines are instructed to find the hidden patterns from the input dataset.

Let's take an example to understand it more preciously; suppose there is a basket of fruit images, and we input it into the machine learning model. The images are totally unknown to the model, and the task of the machine is to find the patterns and categories of the objects.

So, now the machine will discover its patterns and differences, such as colour difference, shape difference, and predict the output when it is tested with the test dataset.

##### Categories of Unsupervised Machine Learning

Unsupervised Learning can be further classified into two types, which are given below:

1. **Clustering**
2. **Association**

a) **Clustering**
The clustering technique is used when we want to find the inherent groups from the data. It is a way to group the objects into a cluster such that the objects with the most similarities remain in one group and have fewer or no similarities with the objects of other groups. An example of the clustering algorithm is grouping the customers by their purchasing behaviour.

Some of the popular clustering algorithms are given below:

- K-Means Clustering algorithm
- Mean-shift algorithm
- DBSCAN Algorithm
- Principal Component Analysis
- Independent Component Analysis

b) **Association**
Association rule learning is an unsupervised learning technique, which finds interesting relations among variables within a large dataset. The main aim of this learning algorithm is to find the dependency of one data item on another data item and map those variables accordingly so that it can generate maximum profit. This algorithm is mainly applied in Market Basket analysis, Web usage mining, continuous production, etc.

Some popular algorithms of Association rule learning are Apriori Algorithm, Eclat, FP-growth algorithm.

###### Advantages and Disadvantages of Unsupervised Learning Algorithm

**Advantages:**

- These algorithms can be used for complicated tasks compared to the supervised ones because these algorithms work on the unlabeled dataset.
- Unsupervised algorithms are preferable for various tasks as getting the unlabeled dataset is easier as compared to the labelled dataset.

**Disadvantages:**

- The output of an unsupervised algorithm can be less accurate as the dataset is not labelled, and algorithms are not trained with the exact output in prior.
- Working with Unsupervised learning is more difficult as it works with the unlabelled dataset that does not map with the output.

##### Applications of Unsupervised Learning

- Network Analysis: Unsupervised learning is used for identifying plagiarism and copyright in document network analysis of text data for scholarly articles.
- Recommendation Systems: Recommendation systems widely use unsupervised learning techniques for building recommendation applications for different web applications and e-commerce websites.
- Anomaly Detection: Anomaly detection is a popular application of unsupervised learning, which can identify unusual data points within the dataset. It is used to discover fraudulent transactions.
- Singular Value Decomposition: Singular Value Decomposition or SVD is used to extract particular information from he database. For example, extracting information of each user located at a particular location.

#### 3. Semi-Supervised Learning

**Semi-Supervised Learning** is a type of Machine Learning algorithm that lies between Supervised and Unsupervised machine learning. It represents the intermediate ground between Supervised (With Labelled training data) and Unsupervised learning (with no labelled training data) algorithms and uses the combination of labelled and unlabeled datasets during the training period.

Although Semi-supervised learning is the middle ground between supervised and unsupervised learning and operates on the data that consists of a few labels, it mostly consists of unlabeled data. As labels are costly, but for corporate purposes, they may have few labels. It is completely different from supervised and unsupervised learning as they are based on the presence & absence of labels.

To overcome the drawbacks of supervised learning and unsupervised learning algorithms, the concept of Semi-supervised learning is introduced. The main aim of semi-supervised learning is to effectively use all the available data, rather than only labelled data like in supervised learning. Initially, similar data is clustered along with an unsupervised learning algorithm, and further, it helps to label the unlabeled data into labelled data. It is because labelled data is a comparatively more expensive acquisition than unlabeled data.

We can imagine these algorithms with an example. Supervised learning is where a student is under the supervision of an instructor at home and college. Further, if that student is self-analysing the same concept without any help from the instructor, it comes under unsupervised learning. Under semi-supervised learning, the student has to revise himself after analyzing the same concept under the guidance of an instructor at college.

##### **Advantages and disadvantages of Semi-supervised Learning**

**Advantages:**

- It is simple and easy to understand the algorithm.
- It is highly efficient.
- It is used to solve drawbacks of Supervised and Unsupervised Learning algorithms.

**Disadvantages:**

- Iterations results may not be stable.
- We cannot apply these algorithms to network-level data.
- Accuracy is low.

#### 4. Reinforcement Learning

Reinforcement learning works on a feedback-based process, in which an AI agent (A software component) automatically explore its surrounding by hitting & trail, taking action, learning from experiences, and improving its performance. Agent gets rewarded for each good action and get punished for each bad action; hence the goal of reinforcement learning agent is to maximize the rewards.

In reinforcement learning, there is no labelled data like supervised learning, and agents learn from their experiences only.

The reinforcement learning process is similar to a human being; for example, a child learns various things by experiences in his day-to-day life. An example of reinforcement learning is to play a game, where the Game is the environment, moves of an agent at each step define states, and the goal of the agent is to get a high score. Agent receives feedback in terms of punishment and rewards.

Due to its way of working, reinforcement learning is employed in different fields such as Game theory, Operation Research, Information theory, multi-agent systems.

A reinforcement learning problem can be formalized using Markov Decision Process(MDP). In MDP, the agent constantly interacts with the environment and performs actions; at each action, the environment responds and generates a new state.

##### Categories of Reinforcement Learning

Reinforcement learning is categorized mainly into two types of methods/algorithms:

1. **Positive Reinforcement Learning**: Positive reinforcement learning specifies increasing the tendency that the required behaviour would occur again by adding something. It enhances the strength of the behaviour of the agent and positively impacts it.
2. **Negative Reinforcement Learning**: Negative reinforcement learning works exactly opposite to the positive RL. It increases the tendency that the specific behaviour would occur again by avoiding the negative condition.

##### Real-world Use cases of Reinforcement Learning

- Video Games: RL algorithms are much popular in gaming applications. It is used to gain super-human performance. Some popular games that use RL algorithms are AlphaGO and AlphaGO Zero.
- Resource Management: The "Resource Management with Deep Reinforcement Learning" paper showed that how to use RL in computer to automatically learn and schedule resources to wait for different jobs in order to minimize average job slowdown.
- Robotics: RL is widely being used in Robotics applications. Robots are used in the industrial and manufacturing area, and these robots are made more powerful with reinforcement learning. There are different industries that have their vision of building intelligent robots using AI and Machine learning technology.
- Text Mining: Text-mining, one of the great applications of NLP, is now being implemented with the help of Reinforcement Learning by Salesforce company.

##### **Advantages and Disadvantages of Reinforcement Learning**

**Advantages:**

- It helps in solving complex real-world problems which are difficult to be solved by general techniques.
- The learning model of RL is similar to the learning of human beings; hence most accurate results can be found.
- Helps in achieving long term results.

**Disadvantages:**

- RL algorithms are not preferred for simple problems.
- RL algorithms require huge data and computations.
- Too much reinforcement learning can lead to an overload of states which can weaken the results.
- The curse of dimensionality limits reinforcement learning for real physical systems.

### Based on how the model is trained or updated

#### 1. Batch Learning (Offline Learning)

- In batch learning, the model is trained on the entire dataset at once. The model receives a batch of data, processes it, updates its parameters, and repeats this process iteratively until convergence.
- It's typically done in a controlled environment where data can be collected, curated, and processed before training. Batch learning is suitable for scenarios where the dataset doesn't change rapidly and resources are available for offline training.

#### 2. Online Learning (Incremental Learning)

- Online learning involves updating the model's parameters as new data arrives one piece at a time or in small mini-batches. The model adapts to changing data over time and can make immediate predictions without retraining on the entire dataset.
- This approach is useful when data arrives continuously or when the distribution of data changes frequently.
- It's commonly used for real-time applications like recommendation systems, fraud detection, and dynamic pricing.

- **Batch Learning**:
  - Pros: Can lead to accurate models due to comprehensive training on the entire dataset. Suitable when you have ample computational resources and well-defined training intervals.
  - Cons: Requires a large amount of memory and processing power. It's slower and can be less flexible when dealing with rapidly changing data.

- **Online Learning**:
  - Pros: Adapts to changing data quickly. Well-suited for scenarios where data arrives in streams or updates frequently. It doesn't require retraining the whole model when new data comes in.
  - Cons: Initial model performance might be lower compared to batch learning. Models can become biased if new data doesn't represent the full spectrum.

In practice, hybrid approaches can also be used, combining the advantages of both batch and online learning. For example, you might perform batch training periodically to update the model on accumulated data, while using online learning to make continuous adjustments based on real-time updates.

The choice between batch and online learning depends on the nature of your data, the resources available, the application's requirements, and your desired level of model adaptability.

### Based on how a machine learning algorithm processes and uses data during training and prediction

#### 1. Instance-Based Learning

- Focus: Memorization and comparison of individual training instances.
- Methodology: The algorithm stores the entire training dataset and makes predictions by comparing similarities between new instances and stored instances.
- Approach: It directly uses the data points themselves to make predictions without creating a generalized model.
- Strengths: Can capture complex relationships and adapt to changing patterns in the data.
- Weaknesses: Can be computationally expensive and sensitive to noisy data. Might struggle with high-dimensional data.

#### 2.Model-Based Learning

- Focus: Generalization of patterns and relationships within the data.
- Methodology: The algorithm learns a generalized model from the training data that summarizes the underlying patterns and relationships.
- Approach: It constructs a representation (model) that can make predictions on new, unseen instances based on learned patterns.
- Strengths: Typically faster during the prediction phase, as it doesn't require searching through stored instances. Can handle higher-dimensional data more efficiently.
- Weaknesses: May not capture intricate or complex relationships as well as instance-based methods. The model might not adapt as easily to changing patterns.

These categories are defined based on the core strategies used by the algorithms. Instance-based methods rely on direct comparison of instances, while model-based methods focus on learning a generalized representation of the data. The choice between these categories depends on factors like the nature of the data, computational resources, interpretability requirements, and the problem at hand.

## Machine Learning Challenges

1. **Data Collection:**
   - **Problem:** Gathering suitable, comprehensive, and diverse data for model training.
   - **Solution:** Collect relevant data from various sources, including online repositories, crowdsourcing, and partnerships with data providers.
   - **Techniques:** Web scraping, APIs, data augmentation.

2. **Insufficient Data/Labelled Data:**
   - **Problem:** Having too little data or labeled examples for effective model training.
   - **Solution:** Data augmentation, transfer learning, and active learning to intelligently select the most informative examples for labeling.
   - **Techniques:** Generative Adversarial Networks (GANs), transfer learning, active learning.

3. **Non-Representative Data:**
   - **Problem:** Training data not accurately representing the real-world distribution.
   - **Solution:** Collect a diverse and balanced dataset that encompasses various scenarios.
   - **Techniques:** Data preprocessing, data augmentation, and resampling.

4. **Poor Quality Data:**
   - **Problem:** Inaccurate, noisy, or incomplete data affecting model performance.
   - **Solution:** Clean and preprocess data by handling missing values, outliers, and inconsistencies.
   - **Techniques:** Data cleaning, outlier detection, data imputation.

5. **Irrelevant Features:**
   - **Problem:** Including irrelevant or redundant features, which can lead to poor model performance.
   - **Solution:** Conduct feature selection or extraction to retain only the most relevant features.
   - **Techniques:** Feature selection algorithms (e.g., Recursive Feature Elimination), Principal Component Analysis (PCA).

6. **Overfitting:**
   - **Problem:** Model becomes too complex and performs well on training data but poorly on new data.
   - **Solution:** Regularization techniques (e.g., L1/L2 regularization), using more data, and simplifying the model architecture.
   - **Techniques:** L1/L2 regularization, dropout, early stopping.

7. **Underfitting:**
   - **Problem:** Model is too simple to capture the underlying patterns in the data.
   - **Solution:** Use more complex models, fine-tune hyperparameters, and improve feature engineering.
   - **Techniques:** Using more layers in neural networks, adjusting model complexity.

8. **Software Integration:**
   - **Problem:** Integrating ML models into existing software systems or applications.
   - **Solution:** Create well-documented APIs and interfaces for seamless integration.
   - **Techniques:** RESTful APIs, Docker containers.

9. **Offline Learning/Deployment:**
   - **Problem:** Developing ML models in a controlled environment, but deploying them in dynamic real-world settings.
   - **Solution:** Continuously monitor and update models to adapt to changing conditions.
   - **Techniques:** Online learning, adaptive algorithms.

10. **Cost Involved:**
    - **Problem:** High costs associated with data collection, model development, and deployment.
    - **Solution:** Optimize resource usage, leverage cloud services, and explore open-source tools.
    - **Techniques:** Cloud computing, using pre-trained models.

## Machine Learning Development Life Cycle

1. **Frame the Problem:**
   - **Explanation:** Define the problem clearly, including the objective, scope, and success criteria.
   - **Example:** Predicting whether a customer will churn from a telecom company's subscription service.

2. **Gathering Data:**
   - **Explanation:** Collect relevant data from various sources that can help address the problem.
   - **Example:** Collecting customer data including demographics, usage history, and customer service interactions.

3. **Data Preprocessing:**
   - **Explanation:** Clean and prepare the data for analysis, handling missing values, outliers, and inconsistencies.
   - **Example:** Removing duplicate records and filling in missing age values with average age.

4. **Exploratory Data Analysis (EDA):**
   - **Explanation:** Analyze and visualize the data to understand patterns, trends, and potential insights.
   - **Example:** Creating histograms to show the distribution of customer usage across different services.

5. **Feature Engineering & Selection:**
   - **Explanation:** Create new features and select the most relevant ones to improve model performance.
   - **Example:** Combining call duration and call frequency to create a feature representing total call time.

6. **Model Training, Evaluation & Selection:**
   - **Explanation:** Train different models on the data, evaluate their performance using metrics, and choose the best model.
   - **Example:** Training logistic regression, decision tree, and random forest models to predict customer churn and evaluating their accuracy.

7. **Model Deployment:**
   - **Explanation:** Deploy the chosen model into a production environment to make predictions on new data.
   - **Example:** Deploying the selected model to the telecom company's system to predict customer churn in real-time.

8. **Testing:**
   - **Explanation:** Test the deployed model's performance on new data to ensure it behaves as expected.
   - **Example:** Using a set of new customer data to check if the deployed model accurately predicts churn.

9. **Optimize:**
   - **Explanation:** Continuously monitor and fine-tune the model's performance over time to improve accuracy.
   - **Example:** Regularly updating the model with new data and retraining it to adapt to changing customer behavior.

**Example:**

For instance, consider a problem of predicting whether a loan applicant will default on a loan.
In this scenario:

1. Problem Framing: Define the problem as classifying loan applicants as "default" or "non-default."
2. Data Gathering: Collect applicant data like income, credit score, and employment history.
3. Data Preprocessing: Handle missing values, convert categorical variables, and normalize numeric features.
4. EDA: Visualize income distribution, analyze credit score trends, and identify correlations.
5. Feature Engineering: Create a new feature by combining income and loan amount.
6. Model Training & Selection: Train a logistic regression and a support vector machine model, select SVM based on higher accuracy.
7. Model Deployment: Integrate the SVM model into the bank's loan processing system.
8. Testing: Use new loan applications to test if the model correctly predicts defaults.
9. Optimization: Periodically retrain the model with new data to improve default prediction accuracy.
